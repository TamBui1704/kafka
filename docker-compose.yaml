# version: '3.8'

# services:
#   zookeeper:
#     image: confluentinc/cp-zookeeper:7.8.0
#     hostname: zookeeper
#     container_name: zookeeper
#     ports:
#       - "2181:2181"
#     environment:
#       ZOOKEEPER_CLIENT_PORT: 2181
#       ZOOKEEPER_SERVER_ID: 1
#       ZOOKEEPER_SERVERS: zookeeper:2888:3888

#   kafka:
#     image: confluentinc/cp-kafka:7.8.0
#     hostname: kafka
#     container_name: kafka
#     ports:
#       - "9092:9092"
#       - "29092:29092"
#       - "9999:9999"
#     environment:
#       KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
#       KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
#       KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
#       KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
#       KAFKA_BROKER_ID: 1
#       KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
#       KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
#       KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
#       KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
#       KAFKA_JMX_PORT: 9999
#       KAFKA_JMX_HOSTNAME: ${DOCKER_HOST_IP:-127.0.0.1}
#       KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
#       KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
#       KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
#     depends_on:
#       - zookeeper

#   postgres:
#     image: postgres:15
#     container_name: postgres
#     environment:
#       - POSTGRES_DB=datawarehouse
#       - POSTGRES_USER=postgres
#       - POSTGRES_PASSWORD=password
#     ports:
#       - "5432:5432"
#     volumes:
#       - ./pgdata:/var/lib/postgresql/data
#     restart: always

#   producer:
#     build:
#       context: ./crawler
#     container_name: producer
#     depends_on:
#       - kafka
#     environment:
#       - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
#     restart: on-failure

#   consumer:
#     build:
#       context: ./consumer
#     container_name: consumer
#     depends_on:
#       - kafka
#       - postgres
#     environment:
#       - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
#       - POSTGRES_HOST=postgres
#       - POSTGRES_DB=datawarehouse
#       - POSTGRES_USER=postgres
#       - POSTGRES_PASSWORD=password
#     restart: on-failure




#################################################test
version: '3.8'

networks:
  kafka-net:

services:
  kafka:
    image: apache/kafka:latest
    container_name: kafka
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 3
    ports:
      - "9092:9092"
    healthcheck:
      test: ["CMD-SHELL", "/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092 > /dev/null 2>&1"]
      interval: 10s
      timeout: 10s
      retries: 5

  topic-creator:
    image: apache/kafka:latest
    depends_on:
      kafka:
        condition: service_healthy
    command: >
      sh -c "
        sleep 5 &&
        /opt/kafka/bin/kafka-topics.sh
          --create
          --topic crawldata_Investing
          --bootstrap-server kafka:9092
          --partitions 3
          --replication-factor 1 ||
        echo 'Topic may already exist'
      "

  postgres:
    image: postgres:15
    container_name: postgres
    restart: always
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: DWH_Economy
    volumes:
      - pgdata:/var/lib/postgresql/data

  producer:
    build:
      context: ./crawler
    container_name: producer
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    restart: on-failure
    networks:
      - kafka-net

  consumer:
    build:
      context: ./consumer
    container_name: consumer
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      POSTGRES_HOST: postgres
      POSTGRES_DB: DWH_Economy
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    restart: on-failure
    networks:
      - kafka-net

volumes:
  pgdata: